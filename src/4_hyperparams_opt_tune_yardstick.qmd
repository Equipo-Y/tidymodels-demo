---
title: "Tidymodels Demo Pt. 4"
author: "Jessica Aquino, Pedro Cataño"
format: html
editor: visual
---

# Tuning y evaluación con resampling

En este notebook se realiza el **ajuste de hiperparámetros (*tuning*)** y la **evaluación comparativa** de los modelos definidos en el notebook anterior.

El objetivo principal de esta etapa es:

- optimizar los hiperparámetros de cada modelo
- evaluar su desempeño de forma robusta mediante resampling
- comparar métricas bajo un esquema común y reproducible

Todos los modelos utilizan exactamente el mismo:
- conjunto de entrenamiento
- esquema de preprocesamiento (`recipe`)
- métrica de evaluación

De esta manera, las diferencias observadas en desempeño pueden atribuirse al modelo y no al pipeline de datos.

[Ir a tuning](#tuning)

# 0. Librerías y configuraciones

```{r}
library(tidyverse)
library(tidymodels)
library(skimr)
library(bonsai) # Para conectar lightgbm

set.seed(1812)
```

# 1. Carga del dataset

Fuente del dataset:\
<https://www.kaggle.com/datasets/aravinii/house-price-prediction-treated-dataset>

```{r}
df <- bind_rows(read_csv("../data/df_train.csv"), read_csv("../data/df_test.csv"))
```

# 2. Separando el dataset con rsample

```{r}
# 80% entrenamiento, 20% prueba
data_split <- initial_split(df, prop = 0.8, strata = price)

train_data <- training(data_split)
test_data  <- testing(data_split)
```

# 3. Preprocesamiento con recipes

```{r}
rec <-
  recipe(price ~ ., data = train_data) %>%
  
  # -------------------------
  # Feature engineering
  # -------------------------
  step_mutate(
    # Size & layout
    m2_per_bedroom        = living_in_m2 / bedrooms,
    bathrooms_per_bedroom = real_bathrooms / bedrooms,
    
    # Bathroom structure
    has_multiple_bathrooms = real_bathrooms >= 2,
    
    # Quality aggregation
    quality_score =
      as.integer(has_basement) +
      as.integer(renovated) +
      as.integer(nice_view) +
      as.integer(perfect_condition) +
      as.integer(has_lavatory),
    
    # Temporal abstraction
    quarter = factor(ceiling(month / 3)),
    
    # Ordinal → categorical
    grade = factor(grade, ordered = TRUE),
    quartile_zone = factor(quartile_zone)
  ) %>%
  
  # -------------------------
  # From logical to numeric (for regularized regression)
  # -------------------------
  step_mutate_at(
    all_logical_predictors(),
    fn = as.numeric
  ) %>% 

  
  # -------------------------
  # Roles
  # -------------------------
  update_role(date, new_role = "ID") %>%
  
  # -------------------------
  # Transform continuous predictors ONLY
  # -------------------------
  step_log(living_in_m2, m2_per_bedroom) %>%
  
  step_normalize(
    living_in_m2,
    m2_per_bedroom,
    bathrooms_per_bedroom,
    quality_score
  ) %>%
  
  # -------------------------
  # Encoding
  # -------------------------
  step_dummy(
    all_nominal_predictors(),
    one_hot = TRUE
  ) %>%
  
  # -------------------------
  # Cleanup
  # -------------------------
  step_rm(month) %>%
  step_zv(all_predictors())

```

# 4. Construcción de modelos con parsnip {#modeling}

## Definición de modelos

### 1. Regresión lineal

```{r}
model_lm <- linear_reg() %>%
  set_engine("lm")
```

### 2. Regresión regularizada

```{r}
model_glmnet <- linear_reg(
  penalty = tune(),
  mixture = tune()
) %>%
  set_engine("glmnet")

```

<!-- ### 3. Random forest -->

<!-- ```{r} -->
<!-- model_rf <- rand_forest( -->
<!--   mtry = tune(), -->
<!--   min_n = tune(), -->
<!--   trees = 1000 -->
<!-- ) %>% -->
<!--   set_engine("ranger") %>% -->
<!--   set_mode("regression") -->

<!-- ``` -->

### 4. LightGBM (Gradient Boosting)

```{r}
model_lgbm <- boost_tree(
  trees = tune(),
  tree_depth = tune(),
  learn_rate = tune(),
  mtry = tune(),
  min_n = tune()
) %>%
  set_engine("lightgbm") %>%
  set_mode("regression")

```

# 5. Workflows

## Workflow - Regresión lineal

```{r}
wf_lm <- workflow() %>%
  add_recipe(rec) %>%
  add_model(model_lm)
```

```{r}
fit_lm <- fit(wf_lm, data = train_data)
```

## Workflow - glmnet, Random Forest y LightGBM

```{r}
wf_glmnet <- workflow() %>%
  add_recipe(rec) %>%
  add_model(model_glmnet)
```

<!-- ```{r} -->
<!-- wf_rf <- workflow() %>% -->
<!--   add_recipe(rec) %>% -->
<!--   add_model(model_rf) -->
<!-- ``` -->

```{r}
wf_lgbm <- workflow() %>%
  add_recipe(rec) %>%
  add_model(model_lgbm)
```

# 6. Tuning

## Resampling: validación cruzada

Se utiliza validación cruzada con 5 folds, estratificada por la variable objetivo (`price`), para obtener estimaciones más estables del desempeño de los modelos.

```{r}
set.seed(1812)

cv_folds <- vfold_cv(
  train_data,
  v = 5,
  strata = price
)
```

## Métricas de evaluación

```{r}
reg_metrics <- metric_set(
  rmse,
  rsq,
  mae
)
```


## Tuning – Regresión regularizada (glmnet) 

### Grid de hiperparámetros

```{r}
glmnet_grid <- grid_regular(
  penalty(range = c(-4, 0)),
  mixture(),
  levels = 5
)
```

### Tuning

```{r}
tuned_glmnet <- tune_grid(
  wf_glmnet,
  resamples = cv_folds,
  grid = glmnet_grid,
  metrics = reg_metrics
)
```

```{r}
collect_metrics(tuned_glmnet)
```

<!-- ## Tuning – Random Forest -->

<!-- ### Grid de hiperparámetros -->

<!-- ```{r} -->
<!-- rf_grid <- grid_regular( -->
<!--   mtry(range = c(5, 30)), -->
<!--   min_n(), -->
<!--   levels = 5 -->
<!-- ) -->
<!-- ``` -->

<!-- ### Tuning -->

<!-- ```{r} -->
<!-- tuned_rf <- tune_grid( -->
<!--   wf_rf, -->
<!--   resamples = cv_folds, -->
<!--   grid = rf_grid, -->
<!--   metrics = reg_metrics -->
<!-- ) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- collect_metrics(tuned_rf) -->
<!-- ``` -->


## Tuning – LightGBM

### Grid de hiperparámetros

```{r}
lgbm_params <- parameters(
  trees(),
  tree_depth(),
  learn_rate(range = c(-3, -1)),
  mtry(),
  min_n()
)

lgbm_params <- finalize(
  lgbm_params,
  train_data
)


lgbm_grid <- grid_regular(
  lgbm_params,
  levels = 3
)

```

### Tuning

```{r}
tuned_lgbm <- tune_grid(
  wf_lgbm,
  resamples = cv_folds,
  grid = lgbm_grid,
  metrics = reg_metrics
)
```

```{r}
collect_metrics(tuned_lgbm)
```

## 7. Selección del mejor modelo por métrica

```{r}
best_glmnet <- select_best(tuned_glmnet, metric = "rmse")
# best_rf     <- select_best(tuned_rf, metric = "rmse")
best_lgbm   <- select_best(tuned_lgbm, metric = "rmse")

best_glmnet
# best_rf
best_lgbm
```


## 7. Finalización de workflows

```{r}
final_glmnet <- finalize_workflow(wf_glmnet, best_glmnet)
# final_rf     <- finalize_workflow(wf_rf, best_rf)
final_lgbm   <- finalize_workflow(wf_lgbm, best_lgbm)
```

## 8. Evaluación final sobre el conjunto de prueba

```{r}
fit_glmnet <- fit(final_glmnet, data = train_data)
# fit_rf     <- fit(final_rf, data = train_data)
fit_lgbm   <- fit(final_lgbm, data = train_data)
```

### Predicciones

```{r}
pred_glmnet <- predict(fit_glmnet, test_data) %>%
  bind_cols(test_data %>% select(price)) %>%
  mutate(model = "glmnet")

# pred_rf <- predict(fit_rf, test_data) %>%
#   bind_cols(test_data %>% select(price)) %>%
#   mutate(model = "random_forest")

pred_lgbm <- predict(fit_lgbm, test_data) %>%
  bind_cols(test_data %>% select(price)) %>%
  mutate(model = "lightgbm")
```

## 9. Comparación de métricas

```{r}
all_preds <- bind_rows(
  pred_glmnet,
  # pred_rf,
  pred_lgbm
)

all_preds %>%
  group_by(model) %>%
  metrics(truth = price, estimate = .pred)
```

## 10. Visualización de desempeño

```{r}
all_preds %>%
  ggplot(aes(x = price, y = .pred, color = model)) +
  geom_point(alpha = 0.4) +
  geom_abline(linetype = "dashed") +
  scale_x_log10() +
  scale_y_log10() +
  labs(
    title = "Predicción vs valor real",
    x = "Precio real (log)",
    y = "Precio predicho (log)"
  )
```


## Nota final

En este notebook se realizó el ajuste de hiperparámetros y la evaluación comparativa de distintos modelos de regresión bajo un esquema de resampling común.

El uso de `workflows`, `tune` y `rsample` permite construir pipelines reproducibles, comparables y extensibles, facilitando la selección del modelo más adecuado para el problema.

En un escenario productivo, el siguiente paso podría incluir:
- análisis de importancia de variables
- evaluación de errores por segmento
- validación externa o temporal
