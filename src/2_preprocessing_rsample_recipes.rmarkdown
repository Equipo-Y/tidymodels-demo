---
title: "Tidymodels Demo Pt. 2"
author: "Jessica Aquino, Pedro Cataño"
format: html
editor: visual
---

# Preprocesamiento con rsample y recipes

En este notebook se aborda el **preprocesamiento de los datos** utilizando el ecosistema `tidymodels`. El objetivo principal es preparar el dataset de manera **reproducible, consistente y libre de fuga de información**, dejando los datos listos para la etapa de modelado que se desarrollará en los siguientes notebooks.

En particular, se trabajan tres componentes clave:

1.  Unificación del dataset original
2.  Separación en conjuntos de entrenamiento y prueba con `rsample`
3.  Definición del preprocesamiento mediante `recipes`

# 0. Instalación de paquetes

```{r}
library(tidyverse)
library(tidymodels)
library(skimr)

set.seed(1812)
```

# 1. Carga del dataset

El dataset original se encuentra dividido en archivos de entrenamiento y prueba. Para este proyecto, ambos conjuntos se unifican con el fin de **redefinir la partición** de manera controlada.

Fuente del dataset:\
<https://www.kaggle.com/datasets/aravinii/house-price-prediction-treated-dataset>

```{r}
df <- bind_rows(read_csv("../data/df_train.csv"), read_csv("../data/df_test.csv"))

skim(df)
```

```{r}
summary(df)
```

# 2. Separación del dataset con rsample

Una vez unificados los datos, se procede a generar una nueva partición en conjuntos de entrenamiento y prueba.

Se utiliza una división 80/20, estratificada por la variable objetivo (`price`), con el objetivo de mantener distribuciones similares de precios en ambos conjuntos.

```{r}
# 80% entrenamiento, 20% prueba
data_split <- initial_split(df, prop = 0.8, strata = price)

train_data <- training(data_split)
test_data  <- testing(data_split)
```

A partir de este objeto se obtienen:

-   `train_data`: conjunto utilizado para aprender transformaciones y entrenar modelos
-   `test_data`: conjunto reservado exclusivamente para evaluación

```{r}
summary(train_data)
```

```{r}
summary(test_data)
```

# 3. Preprocesamiento con recipes

El preprocesamiento se define mediante una **receta (`recipe`)**, que describe de forma declarativa todas las transformaciones que se aplicarán a los datos antes del modelado.

La receta se define **únicamente sobre el conjunto de entrenamiento**, ya que cualquier parámetro aprendido (medias, desviaciones, niveles categóricos, etc.) debe provenir solo de estos datos.

```{r}
rec <-
  recipe(price ~ ., data = train_data) %>%
  
  # -------------------------
  # Feature engineering
  # -------------------------
  step_mutate(
    # Size & layout
    m2_per_bedroom        = living_in_m2 / bedrooms,
    bathrooms_per_bedroom = real_bathrooms / bedrooms,
    
    # Bathroom structure
    has_multiple_bathrooms = real_bathrooms >= 2,
    
    # Quality aggregation
    quality_score =
      as.integer(has_basement) +
      as.integer(renovated) +
      as.integer(nice_view) +
      as.integer(perfect_condition) +
      as.integer(has_lavatory),
    
    # Temporal abstraction
    quarter = factor(ceiling(month / 3)),
    
    # Ordinal → categorical
    grade = factor(grade, ordered = TRUE),
    quartile_zone = factor(quartile_zone)
  ) %>%
  
  # -------------------------
  # From logical to numeric (for regularized regression)
  # -------------------------
  step_mutate_at(
    all_logical_predictors(),
    fn = as.numeric
  ) %>% 

  
  # -------------------------
  # Roles
  # -------------------------
  update_role(date, new_role = "ID") %>%
  
  # -------------------------
  # Transform continuous predictors ONLY
  # -------------------------
  step_log(living_in_m2, m2_per_bedroom) %>%
  
  step_normalize(
    living_in_m2,
    m2_per_bedroom,
    bathrooms_per_bedroom,
    quality_score
  ) %>%
  
  # -------------------------
  # Encoding
  # -------------------------
  step_dummy(
    all_nominal_predictors(),
    one_hot = TRUE
  ) %>%
  
  # -------------------------
  # Cleanup
  # -------------------------
  step_rm(month) %>%
  step_zv(all_predictors())

```

```{r}
rec_prep <- prep(rec)
rec_prep
```

```{r}
train_data_proc <- bake(rec_prep, new_data = NULL)
```

```{r}
train_data_proc
```

# Nota final

Separar explícitamente el **preprocesamiento (`recipes`)** del **modelado** permite:

-   reutilizar el mismo pipeline en distintos modelos
-   garantizar transformaciones consistentes entre entrenamiento y prueba
-   evitar errores comunes de fuga de información

En el siguiente notebook se utilizará esta receta dentro de `workflow()` para entrenar y comparar distintos modelos de regresión.

